{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-py37",
      "display_name": "Python (env py37)",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1680822566928,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nclient \u003d dataiku.api_client()\nproject \u003d client.get_project(\"GIT\")\n\nflow \u003d project.get_flow()\nflow_graph \u003d flow.get_graph()\nflow_graph.get_successor_computables().items()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nclient \u003d dataiku.api_client()\nprojects \u003d client.list_project_keys()\ncurrent_connections \u003d []\nfor proj in projects:\n    project \u003d client.get_project(proj)\n    all_datasets \u003d project.list_datasets()\n    for dataset in all_datasets:\n        print(dataset.name)\n            \n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nall_connections \u003d []\ndss_connections \u003d client.list_connections()\nfor conn in dss_connections:\n    connection \u003d client.get_connection(conn)\n    all_connections.append(connection.name)\n    print(connection.name)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dif \u003d []\nfor element in all_connections:\n    if element not in current_connections:\n        dif.append(element)\nprint(dif)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import datetime   \nproject \u003d client.get_project(\"GIT\")\nepoch_time \u003d project.get_timeline(item_count\u003d0)[\u0027createdOn\u0027]/1000\ncreation_datetime \u003d datetime.datetime.fromtimestamp(epoch_time)\ncreation_datetime"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nimport datetime  \nclient \u003d dataiku.api_client()\nprojects \u003d client.list_project_keys()\nfor proj in projects:\n    project \u003d client.get_project(proj) \n    epoch \u003d project.get_flow().start_tool()\n    #print(f\"{project.project_key} | {epoch}\")\n# use signature()\nprint(project.project.get_flow().start_tool().keys())"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nclient \u003d dataiku.api_client()\nprojects \u003d client.list_project_keys()\nfor project_key in projects:\n    project \u003d client.get_project(project_key)\n    for k in project.get_flow().get_graph().get_source_computables():\n        if len(k[\"predecessors\"]) \u003d\u003d 0: #edit here to add/remove successors\n            project_object \u003d client.get_project(project_key)\n            dataset_object \u003d project_object.get_dataset(k[\u0027ref\u0027])\n            creator \u003d dataset_object.get_info().get_raw()[\u0027versioning\u0027][\u0027createdBy\u0027][\u0027displayName\u0027]\n            dataset_type \u003d dataset_object.get_info().get_raw()[\u0027type\u0027]\n            print(f\"Dataset: {k[\u0027ref\u0027]}, Creator: {creator}, Type: {dataset_type}\")\nprint(dataset_object.get_info().get_raw()[\u0027versioning\u0027][\u0027createdBy\u0027][\u0027displayName\u0027])"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vec \u003d [[1,2,3], [4,5,6], [7,8,9]]\n[num for elem in vec for num in elem]"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "matrix \u003d [\n    [1, 2, 3, 4],\n    [5, 6, 7, 8],\n    [9, 10, 11, 12],\n]\ntransposed \u003d []\nfor i in range(4):\n    # the following 3 lines implement the nested listcomp\n    transposed_row \u003d []\n    for row in matrix:\n        transposed_row.append(row[i])\n    print(transposed_row)\n    transposed.append(transposed_row)\nprint(transposed)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(transposed)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "users \u003d client.list_users()\n\n# Get last login date for each user\nfor user in users:\n    last_login \u003d client.\n    print(user[\u0027login\u0027], last_login)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\n\nclient \u003d dataiku.api_client()\ndss_users \u003d client.list_users()\n\nfor user in dss_users:\n    user \u003d client.get_user(user[\u0027login\u0027])\n    lsl \u003d user.get_activity().get_raw()[\u0027lastSuccessfulLogin\u0027]\n    print(f\"user: \u0027{user.login}\u0027 - last successful login: {lsl}\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os.path\nimport unicodedata\nfrom datetime import datetime\nimport dataiku\nimport dataikuapi\nfrom dataiku import pandasutils as pdu\nimport io\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport gstools as gs\nimport string\nfrom scipy.spatial import cKDTree\n \n\ndef my_api_function():\n    folder \u003d dataiku.Folder(\"zNPEXycJ\")\n    with folder.get_download_stream(\"StatPlanet_Afghanistan.zip\") as stream:\n        data \u003d stream.read()\n    gdp \u003d gpd.read_file(io.BytesIO(data))\n    gdp \u003d geopandas.GeoDataFrame(d, crs\u003d4326)\n    gdp \u003d gd.to_crs(3857)\n    #shape_cnt \u003d shape_cnt.to_crs(epsg\u003d3857)\n    return gdf.columns\nmy_api_function()"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}